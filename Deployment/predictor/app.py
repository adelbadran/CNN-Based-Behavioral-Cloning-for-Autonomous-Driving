import uvicorn
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import io
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
import sys

# ØªØ­Ø¯ÙŠØ¯ Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„Ø£ÙˆØ²Ø§Ù†
MODEL_PATH = "nvidia_model_T1_test.pth"
# Ø§ÙØªØ±Ø§Ø¶ Ø£Ù† Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙØ¯Ø®Ù„Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¬Ù‡ÙŠØ² Ù‡Ùˆ (C, H, W)
INPUT_SHAPE = (3, 66, 200)

# ============================
# 1) Model Architecture (Ù…Ø¹ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ø­Ø¬Ù… fc1)
# ============================

class AutonomousCarModel(nn.Module):
    """
    Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© (PilotNet-style) Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø·Ø¨Ù‚Ø© FC Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹.
    """
    def __init__(self, input_shape=INPUT_SHAPE, fc_out=100):
        super(AutonomousCarModel, self).__init__()

        # Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø§Ù„ØªÙØ§Ù (Conv Layers)
        self.conv1 = nn.Conv2d(3, 24, kernel_size=5, stride=2, padding=0)
        self.conv2 = nn.Conv2d(24, 36, kernel_size=5, stride=2, padding=0)
        self.conv3 = nn.Conv2d(36, 48, kernel_size=5, stride=2, padding=0)
        self.conv4 = nn.Conv2d(48, 64, kernel_size=3, stride=1, padding=0)
        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0)

        self.dropout = nn.Dropout(p=0.5)

        # Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù€ Flatten Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ§Ù‹ (Ø³ÙŠÙƒÙˆÙ† 1152 Ù„Ù€ (3, 66, 200))
        try:
            num_flatten = self._get_flatten_size(input_shape)
        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ø³Ø¨Ø¨ Ù…Ø§ (Ù‚Ø¯ ÙŠØ­Ø¯Ø« Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù€ Convs Ø¨Ø¹Ø¯)
            print(f"âš ï¸ Dynamic size calculation failed, using default (1152): {e}")
            num_flatten = 1152 # Ø§Ù„Ø­Ø¬Ù… Ø§Ù„ØµØ­ÙŠØ­ Ù„Ù€ 66x200
        
        print(f"[Model Init] Calculated Flatten features: {num_flatten}")

        # Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù€ FC (Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ø­Ø³ÙˆØ¨)
        self.fc1 = nn.Linear(num_flatten, fc_out)
        self.fc2 = nn.Linear(fc_out, 50)
        self.fc3 = nn.Linear(50, 10)
        self.fc4 = nn.Linear(10, 1)

    def _get_flatten_size(self, input_shape):
        """ÙŠØ­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø¹Ø¯ Ø¢Ø®Ø± Ø·Ø¨Ù‚Ø© Conv."""
        # ÙŠØ¬Ø¨ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù€ Convs Ø£ÙˆÙ„Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§
        conv_layers = [self.conv1, self.conv2, self.conv3, self.conv4, self.conv5]

        with torch.no_grad():
            # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ†Ø³ÙˆØ± ÙˆÙ‡Ù…ÙŠ Ø¨Ø­Ø¬Ù… Ø¯ÙØ¹Ø© (batch) ÙˆØ§Ø­Ø¯
            x = torch.zeros(1, *input_shape)
            
            for conv_layer in conv_layers:
                x = F.elu(conv_layer(x))
            
            x = x.view(1, -1)
            return x.size(1)

    def forward(self, x):
        # ØªÙ…Ø±ÙŠØ± Ø¹Ø¨Ø± Ø·Ø¨Ù‚Ø§Øª Conv
        x = F.elu(self.conv1(x))
        x = F.elu(self.conv2(x))
        x = F.elu(self.conv3(x))
        x = F.elu(self.conv4(x))
        x = F.elu(self.conv5(x))

        # Flattening (ÙŠØªØ­ÙˆÙ„ Ù…Ù† (Batch, C, H, W) Ø¥Ù„Ù‰ (Batch, C*H*W))
        x = x.view(x.size(0), -1)
        x = self.dropout(x)

        # ØªÙ…Ø±ÙŠØ± Ø¹Ø¨Ø± Ø·Ø¨Ù‚Ø§Øª FC
        x = F.elu(self.fc1(x))
        x = F.elu(self.fc2(x))
        x = F.elu(self.fc3(x))
        x = self.fc4(x)
        return x

# ============================
# 2) Load Model and Setup
# ============================

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ù‡Ø§Ø²
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„Ø­Ø¬Ù… Ø§Ù„ØµØ­ÙŠØ­
# Ù„Ø§Ø­Ø¸: Ø­Ø¬Ù… fc1 Ø³ÙŠØªÙ… Ø­Ø³Ø§Ø¨Ù‡ Ø§Ù„Ø¢Ù† (ÙˆØ³ÙŠÙƒÙˆÙ† 1152)
model = AutonomousCarModel(input_shape=INPUT_SHAPE).to(device)


def load_model_safely(model, path, device):
    """
    ØªØ­Ù…ÙŠÙ„ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„ØªÙŠ Ù„Ø§ ØªØªØ·Ø§Ø¨Ù‚ Ø£Ø­Ø¬Ø§Ù…Ù‡Ø§ (Ù…Ø«Ù„ Ø·Ø¨Ù‚Ø© fc1 Ø¨Ø¹Ø¯ ØªØºÙŠÙŠØ± Ø­Ø¬Ù…Ù‡Ø§).
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"Model checkpoint not found at: {path}")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
    checkpoint = torch.load(path, map_location=device)
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ state_dict Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚Ø§Ù…ÙˆØ³ Ø£ÙƒØ¨Ø±
    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint

    # ØªØµÙÙŠØ© Ø§Ù„Ø£ÙˆØ²Ø§Ù† (Filtering): 
    # ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø£ÙˆØ²Ø§Ù† Ø·Ø¨Ù‚Ø§Øª FC (fc1, fc2, fc3, fc4) Ù„Ø£Ù†Ù†Ø§ ØºÙŠØ±Ù†Ø§ Ø­Ø¬Ù… fc1ØŒ 
    # ÙˆØ¨Ø°Ù„Ùƒ Ù†Ø¶Ù…Ù† ØªØ­Ù…ÙŠÙ„ Ø£ÙˆØ²Ø§Ù† Ø·Ø¨Ù‚Ø§Øª Conv ÙÙ‚Ø·.
    new_state_dict = {}
    
    # Ù…ÙØ§ØªÙŠØ­ Ø·Ø¨Ù‚Ø§Øª FC Ø§Ù„ØªÙŠ Ø³Ù†Ù‚ÙˆÙ… Ø¨ØªØ®Ø·ÙŠÙ‡Ø§
    fc_keys_to_skip = ['fc1.weight', 'fc1.bias', 
                       'fc2.weight', 'fc2.bias', 
                       'fc3.weight', 'fc3.bias', 
                       'fc4.weight', 'fc4.bias']
                       
    for k, v in state_dict.items():
        # Ù…Ø¹Ø§Ù„Ø¬Ø© prefix 'module.' Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù‚Ø¯ ØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡ Ø¨Ù€ DataParallel
        key = k.replace('module.', '')
        
        # ØªØ®Ø·ÙŠ Ù…ÙØ§ØªÙŠØ­ FC ØºÙŠØ± Ø§Ù„Ù…ØªÙˆØ§ÙÙ‚Ø©
        if key not in fc_keys_to_skip:
            new_state_dict[key] = v
        else:
            print(f"Skipping incompatible layer weight: {key}")


    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ù€ strict=False Ù„ØªØ¬Ø§Ù‡Ù„ Ù…ÙØ§ØªÙŠØ­ FC Ø§Ù„ØªÙŠ Ù„Ù… Ù†Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„Ù‡Ø§
    load_res = model.load_state_dict(new_state_dict, strict=False)
    
    # ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù€ 'Missing keys' Ù‡Ù†Ø§ Ù„Ø£Ù†Ù‡Ø§ Ø³ØªÙƒÙˆÙ† Ø·Ø¨Ù‚Ø§Øª FC
    if load_res.unexpected_keys:
        print(f"âš ï¸ Warning: Unexpected keys in checkpoint: {load_res.unexpected_keys}")
    
    print(f"Loaded {len(new_state_dict)} compatible layers successfully. Missing layers (expected for FCs): {load_res.missing_keys}")

    return model

# ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
try:
    model = load_model_safely(model, MODEL_PATH, device)
    model.eval()
    print("ğŸ”¥ Model Loaded and Ready for Inference!")
except FileNotFoundError as e:
    print(f"Error: {e}")
    print("Exiting application. Please ensure your model file is present.")
    sys.exit(1)
except Exception as e:
    print(f"An unexpected error occurred during model loading: {e}")
    sys.exit(1)


# ============================
# 3) FastAPI Setup
# ============================

app = FastAPI(title="Autonomous Car Steering Predictor")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================
# 4) Image Preprocessing
# ============================

def preprocess_image(image):
    """
    ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø© Ù„ØªØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ PilotNet.
    """
    # 1) Crop (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø³Ù…Ø§Ø¡ ÙˆØºØ·Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ø±Ø©)
    image_np = np.array(image)
    # Ø¹Ø§Ø¯Ø©Ù‹ ÙŠØªÙ… Ø§Ù‚ØªØµØ§Øµ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø¹Ù„ÙˆÙŠ (Ø§Ù„Ø³Ù…Ø§Ø¡) ÙˆØ§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø³ÙÙ„ÙŠ (ØºØ·Ø§Ø¡ Ø§Ù„Ø³ÙŠØ§Ø±Ø©)
    # Ù„Ù€ 66x200ØŒ Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ø§Ù‚ØªØµØ§Øµ Ù…Ù† 60 Ø¥Ù„Ù‰ 135 (Ø¨Ø§Ø±ØªÙØ§Ø¹ 75 Ø¨ÙƒØ³Ù„)
    image_cropped = image_np[60:135, :, :]

    # 2) Resize Ù„Ù„Ù€ (66, 200) (Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ Ù…Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ø­Ø¬Ù… HxW)
    image_resized = Image.fromarray(image_cropped).resize((200, 66)) # W, H

    # 3) Normalize (ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª Ù…Ù† [0, 255] Ø¥Ù„Ù‰ [0.0, 1.0])
    image_normalized = np.array(image_resized) / 255.0

    # 4) HWC â†’ CHW (Ù…Ù† Height, Width, Channel Ø¥Ù„Ù‰ Channel, Height, Width)
    image_chw = np.transpose(image_normalized, (2, 0, 1))

    # 5) Ø¥Ù„Ù‰ Tensor ÙˆØ¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø§Ù„Ø¯ÙØ¹Ø© (Batch Dimension)
    tensor = torch.tensor(image_chw, dtype=torch.float32).unsqueeze(0).to(device)
    return tensor

# ============================
# 5) Prediction Endpoint
# ============================

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """
    Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø²Ø§ÙˆÙŠØ© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ù…Ù† ØµÙˆØ±Ø© ÙƒØ§Ù…ÙŠØ±Ø§ Ø£Ù…Ø§Ù…ÙŠØ©.
    """
    try:
        image_bytes = await file.read()
        # ÙØªØ­ ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB (Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø´ÙØ§ÙÙŠØ©)
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        
        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØ±Ø©
        tensor_img = preprocess_image(image)

    except Exception as e:
        # Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ ÙˆØ§Ø¶Ø­Ø© ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø£Ùˆ ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØµÙˆØ±Ø©
        raise HTTPException(status_code=400, detail=f"Image processing error: {e}")

    # ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø­Ø¬Ù… Ø§Ù„ØªÙ†Ø³ÙˆØ± Ø§Ù„Ø¢Ù† (1, 3, 66, 200)
    print(f"Tensor shape prepared for model: {tensor_img.shape}")
    
    with torch.no_grad():
        try:
            # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø²Ø§ÙˆÙŠØ© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡
            steering = model(tensor_img).item()
            
        except Exception as e:
            # Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (mat1 and mat2) Ù„Ù† ØªØ¸Ù‡Ø± Ø§Ù„Ø¢Ù† Ø¨Ø³Ø¨Ø¨ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
            print(f"Error in model forward pass: {e}")
            raise HTTPException(status_code=500, detail=f"Model forward pass failed (Internal): {e}")

    # Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù‡ÙŠ Ø²Ø§ÙˆÙŠØ© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ ÙƒÙ‚ÙŠÙ…Ø© Ø¹Ø§Ø¦Ù…Ø©
    return {"steering_angle": float(steering)}

# ============================
# 6) Run Server
# ============================

# Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù…Ù„Ù Ø§Ù„Ø¨Ø§ÙŠØ«ÙˆÙ†ØŒ Ø³ÙŠÙ‚ÙˆÙ… uvicorn Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if __name__ == "__main__":
    # Ù…Ù„Ø§Ø­Ø¸Ø©: ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ø³Ù… Ù…Ù„Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ uvicorn Ù…Ù† "app:app" Ø¥Ù„Ù‰ Ø§Ø³Ù… Ù…Ù„ÙÙƒ Ø§Ù„Ø­Ø§Ù„ÙŠ
    uvicorn.run("autonomous_car_api:app", host="0.0.0.0", port=8000, reload=True)