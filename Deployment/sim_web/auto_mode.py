#!/usr/bin/env python3

import argparse
import base64
from datetime import datetime
from io import BytesIO
import os

import numpy as np
from PIL import Image
import cv2
import torch
import torch.nn as nn

import socketio
import eventlet
import eventlet.wsgi
from flask import Flask, send_from_directory, jsonify

# =============================
# Device & SocketIO Setup
# =============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
sio = socketio.Server(cors_allowed_origins="*", async_mode='eventlet')
app = Flask(__name__, static_folder='.', static_url_path='')

model = None
prev_steering = 0.0
prev_throttle = 0.0
history = []  # Ù„ØªØ®Ø²ÙŠÙ† ÙƒÙ„ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ù„Ù„Ù€ Dashboard


# =============================
# NVIDIA Model Architecture
# =============================
class NvidiaModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 24, kernel_size=5, stride=2),
            nn.ELU(),
            nn.Conv2d(24, 36, kernel_size=5, stride=2),
            nn.ELU(),
            nn.Conv2d(36, 48, kernel_size=5, stride=2),
            nn.ELU(),
            nn.Conv2d(48, 64, kernel_size=3, stride=1),
            nn.ELU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1),
            nn.ELU(),
            nn.Dropout(0.5)
        )
        self.fc_layers = nn.Sequential(
            nn.Linear(64*1*18, 100),
            nn.ELU(),
            nn.Linear(100, 50),
            nn.ELU(),
            nn.Linear(50, 10),
            nn.ELU(),
            nn.Linear(10, 1)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)
        x = self.fc_layers(x)
        return x


def build_nvidia_model():
    return NvidiaModel().to(device)


# =============================
# Image Preprocessing
# =============================
def preprocess(image):
    if image is None:
        raise ValueError("Image is None")
    h, w = image.shape[:2]
    y1, y2 = 60, 135
    x1, x2 = 0, min(320, w)

    if h < y2 or w < x2:
        cy, cx = h // 2, w // 2
        half_h, half_w = 75 // 2, 320 // 2
        y1 = max(0, cy - half_h)
        y2 = min(h, cy + half_h)
        x1 = max(0, cx - half_w)
        x2 = min(w, cx + half_w)

    image = image[y1:y2, x1:x2]
    image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)
    image = cv2.GaussianBlur(image, (3,3), 0)
    image = cv2.resize(image, (200,66), interpolation=cv2.INTER_AREA)
    image = image.astype(np.float32) / 255.0
    image = np.transpose(image, (2,0,1))
    return torch.tensor(image, dtype=torch.float32).unsqueeze(0).to(device)


# =============================
# Save image (optional)
# =============================
def save_image_to_folder(img_b64, folder):
    try:
        img_data = base64.b64decode(img_b64)
        img = Image.open(BytesIO(img_data)).convert("RGB")
        timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S_%f")[:-3]
        path = os.path.join(folder, f"{timestamp}.jpg")
        img.save(path)
    except Exception as e:
        print("Save image error:", e)


# =============================
# SocketIO Events
# =============================
@sio.on('telemetry')
def telemetry(sid, data):
    global prev_steering, prev_throttle, model, history, ARGS

    if not data:
        sio.emit('steer', {
            'steering_angle': str(0.0),
            'throttle': str(0.0)
        }, skip_sid=True)
        return

    try:
        speed = float(data.get("speed", 0.0))
        img_b64 = data["image"]

        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        if ARGS.image_folder:
            save_image_to_folder(img_b64, ARGS.image_folder)

        # ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„ØµÙˆØ±Ø©
        img = Image.open(BytesIO(base64.b64decode(img_b64))).convert("RGB")
        img_array = np.asarray(img)

        # Ø§Ù„ØªÙ†Ø¨Ø¤
        tensor = preprocess(img_array)
        with torch.no_grad():
            raw_steering = float(model(tensor).item())

        # ØªØµØ­ÙŠØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
        if ARGS.camera == "left":
            raw_steering += ARGS.steer_correction
        elif ARGS.camera == "right":
            raw_steering -= ARGS.steer_correction

        curve = abs(raw_steering)

        # ===== Ù†Ø¸Ø§Ù… Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„ØªÙƒÙŠÙÙŠ Ø­Ø³Ø¨ Ø§Ù„ØªØµÙ†ÙŠÙ =====
        
        # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ù†Ø¹Ø·Ù ÙˆØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© + ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø²Ø§ÙˆÙŠØ©
        if curve > 0.8:
            # Ø®Ø·ÙŠØ± Ø¬Ø¯Ø§Ù‹ - Ø§Ø³ØªØ¬Ø§Ø¨Ø© 95% + ØªÙƒØ¨ÙŠØ± Ù‚ÙˆÙŠ Ù„Ù„Ø²Ø§ÙˆÙŠØ©
            category = "EXTREME"
            response = 0.95
            boost = 1.5 + (curve - 0.8) * 4.0  # ØªÙƒØ¨ÙŠØ± Ù‚ÙˆÙŠ Ø¬Ø¯Ø§Ù‹
            
        elif curve > 0.65:
            # Ø­Ø§Ø¯ Ø¬Ø¯Ø§Ù‹ - Ø§Ø³ØªØ¬Ø§Ø¨Ø© 90% + ØªÙƒØ¨ÙŠØ± Ø¹Ø§Ù„ÙŠ
            category = "VERY_SHARP"
            response = 0.90
            boost = 1.4 + (curve - 0.65) * 3.0  # ØªÙƒØ¨ÙŠØ± Ø¹Ø§Ù„ÙŠ
            
        elif curve > 0.5:
            # Ø­Ø§Ø¯ - Ø§Ø³ØªØ¬Ø§Ø¨Ø© 85% + ØªÙƒØ¨ÙŠØ± Ù…ØªÙˆØ³Ø·/Ø¹Ø§Ù„ÙŠ
            category = "SHARP"
            response = 0.85
            boost = 1.3 + (curve - 0.5) * 2.5  # ØªÙƒØ¨ÙŠØ± Ø¬ÙŠØ¯
            
        elif curve > 0.35:
            # Ù…ØªÙˆØ³Ø· - Ø§Ø³ØªØ¬Ø§Ø¨Ø© 70% + ØªÙƒØ¨ÙŠØ± Ù…ØªÙˆØ³Ø·
            category = "MEDIUM"
            response = 0.70
            boost = 1.2 + (curve - 0.35) * 1.8  # ØªÙƒØ¨ÙŠØ± Ù…Ø¹ØªØ¯Ù„
            
        elif curve > 0.2:
            # Ø®ÙÙŠÙ - Ø§Ø³ØªØ¬Ø§Ø¨Ø© 55% + ØªÙƒØ¨ÙŠØ± Ø®ÙÙŠÙ
            category = "GENTLE"
            response = 0.55
            boost = 1.1 + (curve - 0.2) * 1.2  # ØªÙƒØ¨ÙŠØ± Ø®ÙÙŠÙ
            
        else:
            # Ù…Ø³ØªÙ‚ÙŠÙ… - Ø§Ø³ØªØ¬Ø§Ø¨Ø© 40% + Ø¨Ø¯ÙˆÙ† ØªÙƒØ¨ÙŠØ±
            category = "STRAIGHT"
            response = 0.40
            boost = 1.0

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙƒØ¨ÙŠØ± ÙˆØ§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
        steering = raw_steering * boost
        steering = response * steering + (1 - response) * prev_steering
        
        prev_steering = steering
        steering = np.clip(steering, -1.0, 1.0)
        curve = abs(steering)

        # ===== Ø³Ø±Ø¹Ø§Øª Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§Ù‹ Ø­Ø³Ø¨ Ø§Ù„ØªØµÙ†ÙŠÙ =====
        
        if category == "EXTREME":
            # Ù…Ù†Ø¹Ø·Ù Ø®Ø·ÙŠØ± - Ø³Ø±Ø¹Ø© Ø¨Ø·ÙŠØ¦Ø© Ø¬Ø¯Ø§Ù‹ Ø¬Ø¯Ø§Ù‹
            if speed > 7:
                throttle = -0.5
            elif speed > 5:
                throttle = -0.1
            elif speed > 3:
                throttle = 0.05
            else:
                throttle = 0.15
            throttle_smooth = 0.85  # Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø³Ø±ÙŠØ¹Ø© Ù„Ù„ÙØ±Ù…Ù„Ø©
                
        elif category == "VERY_SHARP":
            # Ù…Ù†Ø¹Ø·Ù Ø­Ø§Ø¯ Ø¬Ø¯Ø§Ù‹ - Ø³Ø±Ø¹Ø© Ù…Ù†Ø®ÙØ¶Ø©
            if speed > 10:
                throttle = -0.35
            elif speed > 7:
                throttle = -0.05
            elif speed > 5:
                throttle = 0.08
            else:
                throttle = 0.18
            throttle_smooth = 0.8
                
        elif category == "SHARP":
            # Ù…Ù†Ø¹Ø·Ù Ø­Ø§Ø¯ - Ø³Ø±Ø¹Ø© Ù…Ø­Ø¯ÙˆØ¯Ø©
            if speed > 13:
                throttle = -0.2
            elif speed > 9:
                throttle = 0.0
            elif speed > 7:
                throttle = 0.12
            else:
                throttle = 0.23
            throttle_smooth = 0.75
                
        elif category == "MEDIUM":
            # Ù…Ù†Ø¹Ø·Ù Ù…ØªÙˆØ³Ø· - Ø³Ø±Ø¹Ø© Ù…Ø¹ØªØ¯Ù„Ø©
            if speed > 17:
                throttle = -0.05
            elif speed > 13:
                throttle = 0.12
            elif speed > 9:
                throttle = 0.22
            else:
                throttle = 0.32
            throttle_smooth = 0.6
                
        elif category == "GENTLE":
            # Ù…Ù†Ø¹Ø·Ù Ø®ÙÙŠÙ - Ø³Ø±Ø¹Ø© Ø¬ÙŠØ¯Ø©
            if speed > 20:
                throttle = 0.18
            elif speed > 15:
                throttle = 0.3
            else:
                throttle = 0.42
            throttle_smooth = 0.45
                
        else:  # STRAIGHT
            # Ù…Ø³ØªÙ‚ÙŠÙ… - Ø³Ø±Ø¹Ø© Ù‡Ø§Ø¯Ø¦Ø©
            if speed < 18:
                throttle = 0.52
            elif speed < 23:
                throttle = 0.38
            else:
                throttle = 0.25
            throttle_smooth = 0.35

        # ØªÙ†Ø¹ÙŠÙ… Ø§Ù„Ø«Ø±ÙˆØªÙ„ Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©
        throttle = throttle_smooth * throttle + (1 - throttle_smooth) * prev_throttle
        prev_throttle = throttle
        throttle = np.clip(throttle, -1.0, ARGS.max_throttle)

        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ù„Ù€ Dashboard
        history.append({
            "timestamp": len(history),
            "steering_angle": steering,
            "speed": speed,
            "throttle": throttle
        })

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ù„Ù„Ø³ÙŠÙ…ÙŠÙˆÙ„Ø§ØªØ±
        sio.emit('steer', {
            'steering_angle': str(steering),
            'throttle': str(throttle)
        }, skip_sid=True)

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© (Ø§Ù„Ù€ View + Dashboard)
        sio.emit('web_telemetry', {
            'image_b64': img_b64,
            'steering': round(steering, 4),
            'speed': round(speed, 2),
            'throttle': round(throttle, 3)
        }, skip_sid=True)

        # Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ø­Ø³Ø¨ Ø§Ù„ÙØ¦Ø©
        emoji = {
            "EXTREME": "ğŸ”´",
            "VERY_SHARP": "ğŸŸ ", 
            "SHARP": "ğŸŸ¡",
            "MEDIUM": "ğŸŸ¢",
            "GENTLE": "ğŸ”µ",
            "STRAIGHT": "âšª"
        }
        
        print(f"{datetime.now().strftime('%H:%M:%S')} {emoji[category]} {category:12s} | "
              f"Rsp:{response:.0%} Bst:{boost:.2f}x | S:{steering:+.3f} | T:{throttle:+.3f} | "
              f"Spd:{speed:4.1f} | C:{curve:.3f}")

    except Exception as e:
        print("Telemetry error:", e)


@sio.on('connect')
def connect(sid, environ):
    global prev_steering, prev_throttle
    prev_steering = 0.0
    prev_throttle = 0.0
    print("\nğŸ¯ ENHANCED CORNERING SYSTEM")
    print("=" * 70)
    print("Category      | Response | Angle Boost | Speed Range")
    print("-" * 70)
    print("ğŸ”´ EXTREME    |   95%    |  1.5x-2.7x  | 3-7 km/h   (Max turn)")
    print("ğŸŸ  VERY_SHARP |   90%    |  1.4x-1.9x  | 5-10 km/h  (High turn)")
    print("ğŸŸ¡ SHARP      |   85%    |  1.3x-1.7x  | 7-13 km/h  (Strong turn)")
    print("ğŸŸ¢ MEDIUM     |   70%    |  1.2x-1.5x  | 9-17 km/h  (Moderate turn)")
    print("ğŸ”µ GENTLE     |   55%    |  1.1x-1.3x  | 15-20 km/h (Light turn)")
    print("âšª STRAIGHT   |   40%    |  1.0x       | 18-23 km/h (No turn)")
    print("=" * 70 + "\n")
    print(f"Simulator connected: {sid}")


# =============================
# API Ù„Ù„Ù€ Dashboard
# =============================
@app.route('/health')
def health():
    return "OK", 200

@app.route('/stats')
def stats():
    if not history:
        return jsonify({"total_predictions":0,"avg_steering":0,"max_steering":0,"std_steering":0})
    angles = [h['steering_angle'] for h in history]
    return jsonify({
        "total_predictions": len(history),
        "avg_steering": round(np.mean(angles), 4),
        "max_steering": round(np.max(np.abs(angles)), 4),
        "std_steering": round(np.std(angles), 4)
    })

@app.route('/history')
def get_history():
    return jsonify({"history": history})


# =============================
# Serve static files (HTML, JS, assets)
# =============================
@app.route('/')
def index():
    return send_from_directory('.', 'index.html')

@app.route('/<path:filename>')
def static_files(filename):
    return send_from_directory('.', filename)


# =============================
# Main
# =============================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('model', type=str, help='Path to .pth model')
    parser.add_argument('--image_folder', type=str, default='', help='Folder to save images')
    parser.add_argument('--camera', type=str, default='center', choices=['center','left','right'])
    parser.add_argument('--steer_correction', type=float, default=0.25)
    parser.add_argument('--max_throttle', type=float, default=0.65)
    parser.add_argument('--port', type=int, default=4567)
    global ARGS
    ARGS = parser.parse_args()

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
    model = build_nvidia_model()
    checkpoint = torch.load(ARGS.model, map_location=device)
    if isinstance(checkpoint, dict):
        key = 'model_state_dict' if 'model_state_dict' in checkpoint else \
              'state_dict' if 'state_dict' in checkpoint else None
        model.load_state_dict(checkpoint[key] if key else checkpoint)
    else:
        model.load_state_dict(checkpoint)
    model.eval()
    print("Model loaded")

    if ARGS.image_folder:
        os.makedirs(ARGS.image_folder, exist_ok=True)
        print(f"Images will be saved to: {ARGS.image_folder}")

    # Ø±Ø¨Ø· SocketIO Ù…Ø¹ Flask
    wrapped_app = socketio.Middleware(sio, app)

    print("\n" + "="*70)
    print("Ø³ÙŠØ±ÙØ± Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ø°Ø§ØªÙŠØ© + Dashboard Ø´ØºØ§Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
    print(f"Ø§ÙØªØ­ÙŠ Ø§Ù„Ù…ØªØµÙØ­ ÙˆØ±Ø§Ø­ÙŠ Ø¹Ù„Ù‰:")
    print(f"        http://127.0.0.1:{ARGS.port}")
    print("="*70 + "\n")

    eventlet.wsgi.server(eventlet.listen(('', ARGS.port)), wrapped_app)