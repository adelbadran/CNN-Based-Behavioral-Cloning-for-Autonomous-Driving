{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR-Zf5SQUUGe"
      },
      "source": [
        "# Environment\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AleRK9AMBnpZ"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "bb5tXNO7qX2Q",
        "outputId": "6dcba18e-0e04-4919-a911-0b49303a6ad9"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4j3kMW6rjDt"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "POoFIgdTru97",
        "outputId": "4cb737bb-4481-4f2c-c6f7-90f706bc5dd6"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d zaynena/selfdriving-car-simulator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E6AslVQtsA5w",
        "outputId": "aadff992-f320-41cb-eeb2-7d02bdd14481"
      },
      "outputs": [],
      "source": [
        "!unzip selfdriving-car-simulator.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tr39RZODfbK"
      },
      "source": [
        "## Prepare the libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOZlDEZsEq2N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import warnings\n",
        "from typing import Tuple\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import ntpath\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import timm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF0xbimKigOW"
      },
      "source": [
        "# Data understanding\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mkxNgPKiUcB"
      },
      "source": [
        "### üì¶ **About Dataset**\n",
        "\n",
        "#### **Context**\n",
        "This is an image dataset generated by the **Udacity Self-Driving Car Simulator**.  \n",
        "The dataset contains driving images from cameras mounted on a virtual vehicle and corresponding driving parameters such as steering angle, throttle, brake, and speed.\n",
        "\n",
        "---\n",
        "\n",
        "### üìÅ **Dataset Structure**\n",
        "\n",
        "| Folder | Description | Size\n",
        "|--------|-------------|------\n",
        "| **track1data/** | Contains images and CSV log file collected only from Track 1 | 31,845\n",
        "| **track2data/** | Contains images and CSV log file collected only from Track 2 | 65,484\n",
        "| **dataset/** | Contains all images from both **track1data/** and **track2data/** combined | 97,329\n",
        "\n",
        "---\n",
        "\n",
        "### üìÑ **CSV File Columns**\n",
        "\n",
        "| Column | Meaning |\n",
        "|--------|---------|\n",
        "| **Center** | Center camera image path |\n",
        "| **Left** | Left camera image path |\n",
        "| **Right** | Right camera image path |\n",
        "| **Steering** | Steering wheel angle |\n",
        "| **Throttle** | Throttle value (acceleration) |\n",
        "| **Brake** | Brake value |\n",
        "| **Speed** | Vehicle speed |\n",
        "\n",
        "---\n",
        "\n",
        "|index|Steering|Throttle|Brake|Speed|\n",
        "|---|---|---|---|---|\n",
        "|count|21828\\.0|21828\\.0|21828\\.0|21828\\.0|\n",
        "|mean|-0\\.01318031883818948|0\\.20500802925959638|0\\.028569632292197635|8\\.782329734606764|\n",
        "|std|0\\.46189122305571556|0\\.28688580517629336|0\\.1198930944174388|2\\.7422589671476296|\n",
        "|min|-1\\.0|0\\.0|0\\.0|1\\.835208e-05|\n",
        "|25%|-0\\.1|0\\.0|0\\.0|7\\.1821675|\n",
        "|50%|0\\.0|0\\.0|0\\.0|8\\.93185|\n",
        "|75%|0\\.05|0\\.3538586|0\\.0|10\\.4863525|\n",
        "|max|1\\.0|1\\.0|1\\.0|19\\.29511|\n",
        "\n",
        "---\n",
        "\n",
        "| Steering Value      | Direction     |\n",
        "|---------------------|---------------|\n",
        "| Less than 0 (`< 0`) | Turn **Right**|\n",
        "| Equal to 0 (`= 0`) | Go **Straight**|\n",
        "| Greater than 0 (`> 0`) | Turn **Left** |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Qchv8QnUp9C"
      },
      "source": [
        "# Data Processing\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX4wecDfFF-m"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "709pgKhCCCBv"
      },
      "outputs": [],
      "source": [
        "# Path to driving log file\n",
        "CSV_PATH = \"/content/data/dataset/dataset/driving_log.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WqbBTvy7CHDu",
        "outputId": "eb837423-4d95-4fe1-c7b2-6b59b29bc163"
      },
      "outputs": [],
      "source": [
        "# Driving log columns\n",
        "COLUMNS = ['Center', 'Left', 'Right', 'Steering', 'Throttle', 'Brake', 'Speed']\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(CSV_PATH, names=COLUMNS)\n",
        "\n",
        "# Preview data\n",
        "data.sample(100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KumVEaEfBnuE",
        "outputId": "ad329a4d-ca93-4958-e2a7-d45e54d3df16"
      },
      "outputs": [],
      "source": [
        "# Show basic information about the dataset\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f_Suy9qVCZ41",
        "outputId": "cab2a732-fc0d-4d8e-b5a6-f29200c331c1"
      },
      "outputs": [],
      "source": [
        "# Show basic statistical summary of the data\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nX4RvNtAUaXk"
      },
      "outputs": [],
      "source": [
        "# Normalize image paths (convert Windows slashes to Unix)\n",
        "def normalize_path(p: str) -> str:\n",
        "    return p.replace(\"\\\\\", \"/\")\n",
        "\n",
        "# Apply normalization\n",
        "for col in [\"Center\", \"Left\", \"Right\"]:\n",
        "    data[col] = data[col].apply(normalize_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NrlTTAo5CLhT",
        "outputId": "78008355-4b81-43aa-e824-ab6ea57bc930"
      },
      "outputs": [],
      "source": [
        "def get_filename(path: str) -> str:\n",
        "    \"\"\"Return filename from full path.\"\"\"\n",
        "    return ntpath.basename(path)\n",
        "\n",
        "# Extract filenames\n",
        "for col in [\"Center\", \"Left\", \"Right\"]:\n",
        "    data[col] = data[col].apply(get_filename)\n",
        "\n",
        "# Preview data\n",
        "data.sample(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmJsSEMuJjVN"
      },
      "source": [
        "## Data balancing\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrxaKCmECNxz",
        "outputId": "f6169391-4e77-4a7f-8d3c-8c94700754c5"
      },
      "outputs": [],
      "source": [
        "# Steering distribution parameters\n",
        "NUM_BINS = 25\n",
        "SAMPLES_PER_BIN = 1600  # Hyperparameter\n",
        "\n",
        "# Steering histogram\n",
        "hist, bins = np.histogram(data[\"Steering\"], bins=NUM_BINS)\n",
        "print(\"Bin edges:\", bins)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "YkdYHGznCUgr",
        "outputId": "c3262447-eb08-43c8-c66c-335aa1c59a93"
      },
      "outputs": [],
      "source": [
        "# Bin centers\n",
        "centers = (bins[:-1] + bins[1:]) / 2\n",
        "\n",
        "# Plot steering distribution\n",
        "plt.bar(centers, hist, width=0.05, edgecolor='k')\n",
        "plt.plot(\n",
        "    [data[\"Steering\"].min(), data[\"Steering\"].max()],\n",
        "    [SAMPLES_PER_BIN, SAMPLES_PER_BIN],\n",
        "    \"r--\",\n",
        "    linewidth=2,\n",
        "    label=f\"Target per bin ({SAMPLES_PER_BIN})\"\n",
        ")\n",
        "\n",
        "plt.title(\"Steering Angle Distribution\")\n",
        "plt.xlabel(\"Steering Angle\")\n",
        "plt.ylabel(\"Sample Count\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k17_rUSLISlZ",
        "outputId": "ebc719be-3de0-4c7d-a7ef-131a2c108f9e"
      },
      "outputs": [],
      "source": [
        "print(f\"Total samples: {len(data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrqaiBXVCW0V"
      },
      "outputs": [],
      "source": [
        "remove_list = []\n",
        "steering_vals = data[\"Steering\"].values\n",
        "\n",
        "for i in range(NUM_BINS):\n",
        "    if i < NUM_BINS - 1:\n",
        "        mask = (steering_vals >= bins[i]) & (steering_vals < bins[i + 1])\n",
        "    else:\n",
        "        mask = (steering_vals >= bins[i]) & (steering_vals <= bins[i + 1])\n",
        "\n",
        "    indices = np.where(mask)[0]\n",
        "    np.random.shuffle(indices)\n",
        "    remove_list.extend(indices[SAMPLES_PER_BIN:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9WhF9YCCY4C",
        "outputId": "d1f2f3ee-cb0e-4fa5-9ef2-a38c6655b2b5"
      },
      "outputs": [],
      "source": [
        "# Balance dataset by dropping excess samples\n",
        "data_balanced = data.drop(remove_list)\n",
        "print(f\"Samples retained: {len(data_balanced)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "ZQznz08PJVTn",
        "outputId": "15aec89b-6880-48cb-9422-1747a06c4e6b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(data[\"Steering\"], bins=NUM_BINS, edgecolor=\"k\")\n",
        "plt.title(\"Original Steering Distribution\")\n",
        "plt.xlabel(\"Steering Angle\")\n",
        "plt.ylabel(\"Sample Count\")\n",
        "\n",
        "# Balanced distribution\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(data_balanced[\"Steering\"], bins=NUM_BINS, edgecolor=\"k\")\n",
        "plt.title(\"Balanced Steering Distribution\")\n",
        "plt.xlabel(\"Steering Angle\")\n",
        "plt.ylabel(\"Sample Count\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eWLmrebJuMV"
      },
      "source": [
        "## Data splitting\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzPirsrSLpVJ"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = '/content/data/dataset/dataset/IMG'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42Mw8s-WJyKV"
      },
      "outputs": [],
      "source": [
        "def load_images_and_steering(data_dir: str, df: pd.DataFrame) -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Load image paths and steering angles with side camera corrections.\"\"\"\n",
        "    image_paths, steerings = [], []\n",
        "\n",
        "    correction = 0.15\n",
        "    for _, row in df.iterrows():\n",
        "        center, left, right = row['Center'], row['Left'], row['Right']\n",
        "        steer = float(row['Steering'])\n",
        "\n",
        "        image_paths.extend([\n",
        "            os.path.join(data_dir, center),\n",
        "            os.path.join(data_dir, left),\n",
        "            os.path.join(data_dir, right),\n",
        "        ])\n",
        "        steerings.extend([\n",
        "            steer,\n",
        "            steer  + correction,\n",
        "            steer - correction,\n",
        "        ])\n",
        "\n",
        "    return np.array(image_paths), np.array(steerings)\n",
        "\n",
        "# Usage\n",
        "image_paths, steerings = load_images_and_steering(DATA_DIR + '/', data_balanced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFyJAv_U01tE",
        "outputId": "11617237-3291-4221-9235-2292894a6db4"
      },
      "outputs": [],
      "source": [
        "# length\n",
        "print(f\"Total images: {len(image_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5qYZzR9UWKk"
      },
      "outputs": [],
      "source": [
        "def fix_path(path: str) -> str:\n",
        "    return path.replace(\"\\\\\", \"/\")\n",
        "\n",
        "for col in [\"Center\", \"Left\", \"Right\"]:\n",
        "    data[col] = data[col].apply(fix_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "27Y9wPDgfT8-",
        "outputId": "fe2d5691-c422-456c-8f52-26ba2fb1333e"
      },
      "outputs": [],
      "source": [
        "# Preview data\n",
        "data.sample(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "7eAPV9sDHWTM",
        "outputId": "1f95e5b3-23e7-4719-9797-78ddbe41cc7d"
      },
      "outputs": [],
      "source": [
        "sample_idx = 10\n",
        "start_idx = sample_idx * 3\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "camera_names = ['Center', 'Left', 'Right']\n",
        "\n",
        "for i in range(3):\n",
        "    img_path = image_paths[start_idx + i]\n",
        "    steering_angle = steerings[start_idx + i]\n",
        "\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f'{camera_names[i]} Camera\\nSteering: {steering_angle:.2f}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYaEyJ9NK1dV",
        "outputId": "11986b06-4e74-4b0d-887f-e83404c02a6b"
      },
      "outputs": [],
      "source": [
        "# Split data: 75% train, 15% validation\n",
        "# Split train: 75% train, 15% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    image_paths, steerings, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_val, y_train, y_val=train_test_split(\n",
        "   X_train, y_train, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Validation samples: {len(X_val)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Ohrq-O73N0eM",
        "outputId": "c86a8181-e798-4fed-a64f-310757204bab"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Training distribution\n",
        "axes[0].hist(y_train, bins=NUM_BINS, width=0.05, color='blue', edgecolor='black')\n",
        "axes[0].set(title='Training Dataset', xlabel='Steering Angle', ylabel='Sample Count')\n",
        "\n",
        "# Validation distribution\n",
        "axes[1].hist(y_val, bins=NUM_BINS, width=0.05, color='red', edgecolor='black')\n",
        "axes[1].set(title='Validation Dataset', xlabel='Steering Angle', ylabel='Sample Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6pb5HTdUPau"
      },
      "source": [
        "## Data augmentation\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1WDY-rUrGv-"
      },
      "outputs": [],
      "source": [
        "def normalize_nvidia(image, **kwargs):\n",
        "    return image.astype(np.float32) / 255.0\n",
        "\n",
        "def get_transforms_list(Nv):\n",
        "    transforms = [\n",
        "        A.Crop(x_min=0, y_min=60, x_max=320, y_max=135, p=1.0),\n",
        "        A.GaussianBlur(blur_limit=3, p=1.0),\n",
        "    ]\n",
        "\n",
        "    if Nv:\n",
        "        transforms.extend([\n",
        "            A.Lambda(image=lambda img, **kwargs: cv2.cvtColor(img, cv2.COLOR_RGB2YUV), p=1.0),\n",
        "            A.Resize(height=66, width=200, interpolation=cv2.INTER_AREA, p=1.0),\n",
        "            A.Lambda(image=normalize_nvidia, p=1.0),\n",
        "        ])\n",
        "    else:\n",
        "        transforms.extend([\n",
        "            A.Resize(height=64, width=192, interpolation=cv2.INTER_AREA, p=1.0),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0),\n",
        "        ])\n",
        "\n",
        "    return transforms\n",
        "\n",
        "def get_train_transforms(Nv):\n",
        "    aug_list = [\n",
        "        A.Affine(scale=(1.0, 1.4), mode=cv2.BORDER_REPLICATE, p=0.5),\n",
        "        A.RandomBrightnessContrast(brightness_limit=(-0.8, 0.2), contrast_limit=0, p=0.5),\n",
        "    ]\n",
        "\n",
        "    full_pipeline = aug_list + get_transforms_list(Nv) + [ToTensorV2(p=1.0)]\n",
        "\n",
        "    return A.Compose(full_pipeline)\n",
        "\n",
        "def get_val_transforms(Nv):\n",
        "    full_pipeline = get_transforms_list(Nv) + [ToTensorV2(p=1.0)]\n",
        "\n",
        "    return A.Compose(full_pipeline)\n",
        "\n",
        "def get_test_transforms(Nv):\n",
        "    full_pipeline = get_transforms_list(Nv) + [ToTensorV2(p=1.0)]\n",
        "\n",
        "    return A.Compose(full_pipeline)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqrcRWe3awVH"
      },
      "source": [
        "# Dataset & DataLoader\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GFNJoFaA1IY"
      },
      "outputs": [],
      "source": [
        "class DrivingDataset(Dataset):\n",
        "    def __init__(self, image_paths, steerings, transform=None, is_train=False) :\n",
        "        self.image_paths = image_paths\n",
        "        self.steerings = steerings\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def _random_flip(self, img, steering):\n",
        "        if random.random() < 0.5:\n",
        "            return cv2.flip(img, 1), -steering\n",
        "        return img, steering\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        steering = self.steerings[idx]\n",
        "\n",
        "        img = np.array(Image.open(img_path).convert('RGB'))\n",
        "\n",
        "        if self.is_train:\n",
        "            img, steering = self._random_flip(img, steering)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)['image']\n",
        "\n",
        "        return img, torch.tensor(steering, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZzIJqhVWRoR",
        "outputId": "13648362-3d1c-4b3a-aa47-ac8f20efe033"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_dataset = DrivingDataset(X_train, y_train, transform=get_train_transforms(True), is_train=True)\n",
        "val_dataset = DrivingDataset(X_val, y_val, transform=get_val_transforms(True))\n",
        "test_dataset = DrivingDataset(X_test, y_test, transform=get_val_transforms(True))\n",
        "\n",
        "print(f\"Training dataset: {len(train_dataset)} samples (with augmentation)\")\n",
        "print(f\"Validation dataset: {len(val_dataset)} samples (no augmentation)\")\n",
        "\n",
        "batch_size = 64\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "print(f\"Train loader: {len(train_loader)} batches per epoch\")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")\n",
        "print(f\"Validation loader: {len(val_loader)} batches per epoch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0DVwNCiNaLq1",
        "outputId": "f156bcfb-e6b8-4c74-9510-f7a90057a87d"
      },
      "outputs": [],
      "source": [
        "num_batches = 3\n",
        "images_per_batch = 20\n",
        "cols = 5\n",
        "rows = (images_per_batch + cols - 1) // cols\n",
        "\n",
        "for batch_idx, (images, steerings) in enumerate(train_loader):\n",
        "    if batch_idx >= num_batches:\n",
        "        break\n",
        "\n",
        "    batch_size = images.size(0)\n",
        "    n_show = min(images_per_batch, batch_size)\n",
        "\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
        "    fig.suptitle(f'Batch {batch_idx + 1}', fontsize=16)\n",
        "    fig.tight_layout(pad=3.0)\n",
        "\n",
        "    for i in range(n_show):\n",
        "        r, c = divmod(i, cols)\n",
        "        img_yuv = images[i].permute(1, 2, 0).cpu().numpy()\n",
        "        img_rgb = cv2.cvtColor((img_yuv * 255).astype(np.uint8), cv2.COLOR_YUV2RGB)\n",
        "\n",
        "        axs[r, c].imshow(img_rgb)\n",
        "        axs[r, c].set_title(f'Steering: {steerings[i].item():.3f}')\n",
        "        axs[r, c].axis('off')\n",
        "\n",
        "    # Remove unused subplots\n",
        "    for j in range(n_show, rows * cols):\n",
        "        r, c = divmod(j, cols)\n",
        "        fig.delaxes(axs[r, c])\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR8PC48CTxFP"
      },
      "source": [
        "# Modeling\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTyCVoai1P4f"
      },
      "source": [
        "## Nvidia model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nayi4zlxezGG"
      },
      "source": [
        "### Model architecture (Nvidia)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoIZ5yJ3hK3K",
        "outputId": "3a975cde-d5c0-4e68-c904-25a0080359a4"
      },
      "outputs": [],
      "source": [
        "class NvidiaModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 24, kernel_size=5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(24, 36, kernel_size=5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(36, 48, kernel_size=5, stride=2),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(48, 64, kernel_size=3, stride=1),\n",
        "            nn.ELU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ELU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(64 * 1 * 18, 100),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(100, 50),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(50, 10),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(10, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc_layers(x)\n",
        "\n",
        "print(\"NvidiaModel class defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpPtNvvySt6l"
      },
      "source": [
        "### Model train (Nvidia)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYFGFu0ohNhU",
        "outputId": "4addd2f7-65f5-45f6-e1bc-00673d1eb968"
      },
      "outputs": [],
      "source": [
        "model = NvidiaModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print(f\"Model ready on {device}. Loss: MSE. Optimizer: Adam.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXJC7ZuGtSqu"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer, device, epoch):\n",
        "    model.train()\n",
        "    running_loss, running_mae = 0.0, 0.0\n",
        "    pbar = tqdm(enumerate(loader), total=len(loader), desc=f\"Epoch {epoch} Training\", ncols=120)\n",
        "\n",
        "    for i, (images, steerings) in pbar:\n",
        "        images, steerings = images.to(device), steerings.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images).squeeze()\n",
        "        loss = criterion(outputs, steerings)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        mae = F.l1_loss(outputs, steerings, reduction='mean').item()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_mae += mae\n",
        "\n",
        "        pbar.set_postfix(loss=f\"{running_loss/(i+1):.4f}\", MAE=f\"{running_mae/(i+1):.4f}\")\n",
        "\n",
        "    return running_loss / len(loader), running_mae / len(loader)\n",
        "\n",
        "def validate(model, loader, criterion, device, epoch):\n",
        "    model.eval()\n",
        "    running_loss, running_mae = 0.0, 0.0\n",
        "    pbar = tqdm(enumerate(loader), total=len(loader), desc=f\"Epoch {epoch} Validation\", ncols=120)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, steerings) in pbar:\n",
        "            images, steerings = images.to(device), steerings.to(device)\n",
        "            outputs = model(images).squeeze()\n",
        "            loss = criterion(outputs, steerings)\n",
        "            mae = F.l1_loss(outputs, steerings, reduction='mean').item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_mae += mae\n",
        "\n",
        "            pbar.set_postfix(loss=f\"{running_loss/(i+1):.4f}\", MAE=f\"{running_mae/(i+1):.4f}\")\n",
        "\n",
        "    return running_loss / len(loader), running_mae / len(loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PbfuIpLtTxX",
        "outputId": "ea6999e2-abb4-4bac-90ae-d5292dbbd70b"
      },
      "outputs": [],
      "source": [
        "best_val_loss = float('inf')\n",
        "num_epochs = 25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_mae = train(model, train_loader, criterion, optimizer, device, epoch)\n",
        "    val_loss, val_mae = validate(model, val_loader, criterion, device, epoch)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train: Loss={train_loss:.4f}, MAE={train_mae:.4f} | \"\n",
        "          f\"Val: Loss={val_loss:.4f}, MAE={val_mae:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"nvidia_model.pth\")\n",
        "        print(f\"Saved best model at epoch {epoch+1} with val loss: {val_loss:.4f}\")\n",
        "\n",
        "print(\"Training complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN6H7NWFbfWm",
        "outputId": "03c9f20d-7bbc-4ac1-ede9-75a6d460a4b7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "model = NvidiaModel()\n",
        "model.load_state_dict(torch.load(\"nvidia_model.pth\", map_location=\"cpu\"))\n",
        "\n",
        "print(\"Loaded model.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0.0\n",
        "test_mae = 0.0\n",
        "total_samples = 0\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    loop_test = tqdm(test_loader, desc=\"[Testing]\", leave=True)\n",
        "\n",
        "    for imgs, y in loop_test:\n",
        "        imgs = imgs.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        preds = model(imgs).squeeze()\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        test_loss += loss.item() * imgs.size(0)\n",
        "        test_mae += torch.abs(preds - y).sum().item()\n",
        "        total_samples += imgs.size(0)\n",
        "\n",
        "final_test_loss = test_loss / total_samples\n",
        "final_test_mae = test_mae / total_samples\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FINAL TEST RESULTS\")\n",
        "print(f\"Total Samples: {total_samples}\")\n",
        "print(f\"Final MSE Loss: {final_test_loss:.4f}\")\n",
        "print(f\"Final MAE: {final_test_mae:.4f}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WJgZg5ngfjr"
      },
      "source": [
        "## ViT Model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCIXJMmKc7xT"
      },
      "outputs": [],
      "source": [
        "train_dataset = DrivingDataset(X_train, y_train, transform=get_train_transforms(False), is_train=True)\n",
        "val_dataset   = DrivingDataset(X_val,   y_val, transform=get_val_transforms(False))\n",
        "test_dataset   = DrivingDataset( X_test, y_test, transform=get_test_transforms(False))\n",
        "\n",
        "#----\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader   = DataLoader(test_dataset,   batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coD9abJjjgNX"
      },
      "outputs": [],
      "source": [
        "class ViTRegression(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model_name='vit_tiny_patch16_224',\n",
        "                 pretrained=True,\n",
        "                 drop_rate=0.1,\n",
        "                 img_size=(64, 192)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = timm.create_model(\n",
        "            model_name,\n",
        "            pretrained=pretrained,\n",
        "            num_classes=0,\n",
        "            global_pool='avg',\n",
        "            img_size=img_size,\n",
        "            dynamic_img_size=True\n",
        "        )\n",
        "\n",
        "        features = self.backbone.num_features\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(features, 256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_rate),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.backbone(x)\n",
        "        out = self.head(feats)\n",
        "        return out.squeeze(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puBBETLgl2hw",
        "outputId": "f29f6f25-4a44-49b3-dca7-36660da0991b"
      },
      "outputs": [],
      "source": [
        "model =ViTRegression().to(device)\n",
        "for param in model.backbone.parameters(): # \"freeze\"\n",
        "    param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akHpu2OwmFHk"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFhJ_3ZEggP9",
        "outputId": "affc532f-2486-44c2-b269-125bdf452bc5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss, running_mae = 0.0, 0.0\n",
        "    train_preds, train_targets = [], []\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\", leave=False)\n",
        "\n",
        "    for imgs, y in loop:\n",
        "        imgs, y = imgs.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(imgs).squeeze()\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        running_mae += torch.abs(preds - y).sum().item()\n",
        "\n",
        "        train_preds.extend(preds.detach().cpu().numpy())\n",
        "        train_targets.extend(y.detach().cpu().numpy())\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_mae = running_mae / len(train_loader.dataset)\n",
        "\n",
        "    model.eval()\n",
        "    running_loss, running_mae = 0.0, 0.0\n",
        "    val_preds, val_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loop_val = tqdm(val_loader, desc=f\"Epoch {epoch+1} [Val]\", leave=False)\n",
        "        for imgs, y in loop_val:\n",
        "            imgs, y = imgs.to(device), y.to(device)\n",
        "            preds = model(imgs).squeeze()\n",
        "            loss = criterion(preds, y)\n",
        "\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            running_mae += torch.abs(preds - y).sum().item()\n",
        "\n",
        "            val_preds.extend(preds.cpu().numpy())\n",
        "            val_targets.extend(y.cpu().numpy())\n",
        "\n",
        "    val_loss = running_loss / len(val_loader.dataset)\n",
        "    val_mae = running_mae / len(val_loader.dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train: Loss={train_loss:.4f}, MAE={train_mae:.4f}| \"\n",
        "          f\"Val: Loss={val_loss:.4f}, MAE={val_mae:.4f}\")\n",
        "\n",
        "\n",
        "    if epoch == 3:\n",
        "        for param in model.backbone.parameters():\n",
        "            param.requires_grad = True\n",
        "        optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-6)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), \"vit_best_steering.pth\")\n",
        "        print(f\"Saved best model (Loss: {val_loss:.4f})\")\n",
        "\n",
        "print(\"Training Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW3JQhwsOB1j",
        "outputId": "d43a64cb-ace3-402f-fb37-4c573c037f18"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    model.load_state_dict(torch.load(\"vit_best_steering.pth\"))\n",
        "    print(\"‚úÖ Loaded best model weights successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ö†Ô∏è Error: vit_best_steering.pth not found. Ensure training completed and saved the file.\")\n",
        "    exit()\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "test_mae = 0.0\n",
        "total_samples = 0\n",
        "\n",
        "print(\"\\n‚ñ∂Ô∏è Starting Test Set Evaluation...\")\n",
        "with torch.no_grad():\n",
        "    loop_test = tqdm(test_loader, desc=\"[Testing]\", leave=True)\n",
        "    for imgs, y in loop_test:\n",
        "        imgs, y = imgs.to(device), y.to(device)\n",
        "\n",
        "        preds = model(imgs).squeeze()\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        test_loss += loss.item() * imgs.size(0)\n",
        "        test_mae += torch.abs(preds - y).sum().item()\n",
        "        total_samples += imgs.size(0)\n",
        "\n",
        "final_test_loss = test_loss / total_samples\n",
        "final_test_mae = test_mae / total_samples\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"üèÅ Final Test Results\")\n",
        "print(f\"| Test Samples: {total_samples}\")\n",
        "print(f\"| Final Test MSE Loss: {final_test_loss:.4f}\")\n",
        "print(f\"| Final Test MAE: {final_test_mae:.4f}\")\n",
        "print(\"=\" * 50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yR-Zf5SQUUGe",
        "AleRK9AMBnpZ",
        "9Tr39RZODfbK",
        "bF0xbimKigOW",
        "5Qchv8QnUp9C",
        "mX4wecDfFF-m",
        "TmJsSEMuJjVN",
        "4eWLmrebJuMV",
        "d6pb5HTdUPau",
        "FbxA-tP_rHus",
        "OqrcRWe3awVH",
        "nayi4zlxezGG",
        "lpPtNvvySt6l"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
